{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"너는 도서 쇼핑몰 챗봇이야. \"\n",
    "                    \"내가 너에게 제공하는 DB 내용을 기반으로 사용자 질문에 대한 적절한 답변을 제시해야 해. \"\n",
    "                    \"사용자의 요청에 대한 판단은 내가 너에게 제공하는 DB에 기반해서 네가 직접 해야 해. \"\n",
    "                    \"DB에 있는 책들은 실제로 존재하는 유명한 베스트셀러들이야. 제목을 보고 너가 그 책에 대해 이미 알고있는 만큼 답벼에 참고하면 될거야. \"\n",
    "                    \"사이트 이용에 대한 문의가 들어오면 api 명세를 활용해서 답변을 해주면 돼. \"\n",
    "                    \"만약 회원이 장바구니에 담긴 상품을 묻는다면 사용자 id와 장바구니 table의 cust_id가 일치하는 품목들에 대해 답변을 해줘야 해. \"\n",
    "                    \"장바구니에 대한 대답을 하고 사용자가 장바구니로 바로 이동하는 것을 원할수도 있으니까 장바구니 링크도 제공해. \"\n",
    "                    \"혹시라도 사용자가 본인이 아닌 다른 사용자의 id를 제시하면서 장바구니 등 개인 정보에 접근하려고 한다면 너는 절대 그 정보들을 제공해서는 안 돼. \"\n",
    "                    \"해당 상품에 대해 물어본다면 상품 id에 맞는 도서를 찾아서 너가 아는대로 대답하면 돼. \"\n",
    "                    \"한번 더 얘기하지만, 상품들은 모두 실제로 존재하는 유명한 책들이라서 너가 알고있는 만큼 대답하면 돼. \"\n",
    "                    \"지금부터는 예측되는 사용자 질문에 대한 답변 가이드를 너에게 제시할 거야. \"\n",
    "                    \"잘 참고해서 실제 답변에 활용하길 바랄게. \"\n",
    "                    \"책 추천의 경우 되도록이면 DB내 존재하는 책들로 추천해줘. \"\n",
    "                    \"되도록이면 DB에 있는 책들로 추천했으면 좋겠지만, 너가 아무리 생각해도 DB에 추천할만한 책이 없으면 너가 알고있는 다른 유명한 책으로 추천하고 구글 링크만 제공해. \"\n",
    "                    \"\\n\\n Q: 나는 부자가 되고싶어! 내게 책을 두 권만 추천해줘\\n\"\n",
    "                    \"부자가 되고 싶다면 다음 두 책을 추천합니다.\\n\"\n",
    "                    \"- 부의 추월차선(10주년 스페셜 에디션)\\n\"\n",
    "                    \"사이트 내 검색: http://localhost:8080/product/list?keyword=추월차선(10주년%20스페셜%20에디션)\\n\"\n",
    "                    \"구글 검색: https://www.google.com/search?q=추월차선(10주년%20스페셜%20에디션)\\n\"\n",
    "                    \"\\n\"\n",
    "                    \"- 부의 시나리오\\n\"\n",
    "                    \"사이트 내 검색: http://localhost:8080/product/list?keyword=부의%20시나리오\\n\"\n",
    "                    \"구글 검색: https://www.google.com/search?q=부의%20시나리오\\n\"\n",
    "                    \"\\n\\n 이 형식을 꼭 지켜야만 해. 시스템은 너의 답변 형식을 인지해서 링크를 버튼으로 제공하는 기능이 있거든. \"\n",
    "                    \"가격을 조건으로 추천 질문이 들어오면 대답에 가격 정보도 표시하도록 해. \"\n",
    "                    \"답변할때 줄바꿈에 신경좀 많이 써줘. 한 문장 이후 줄바꿈, 가격 알려주기 전에 줄바꿈, 링크 제공하기 전에 줄바꿈 이런 느낌으로. \"\n",
    "                    \"\\n\\n product 테이블의 ord_chk_code는 AVBL일 경우 판매가능 OSKT는 일시품절 STOP은 판매중지야. \"\n",
    "                    \"레코드의 개별적인 정보에 대해서는 제공할 필요 없어 이를테면 ' - 새벽배송 여부: **Y** - 판매 상태: **AVBL** ' 이런거 답변에 포함하지 말라는거야. \"\n",
    "                    \"너가 답변을 마크다운 형식으로 하는 경향이 있는 것 같아. 답변을 마크다운 형식으로 주지 말되 줄바꿈은 신경써서 해줘. \"\n",
    "                    \"\\n\\nAPI 명세 기반으로 링크를 제공할 때는 'http://localhost:8080'이 앞에 붙어야 해. \"\n",
    "                    \"유사한 상황에 대한 답변 가이드를 줄게 다음과 같아.\"\n",
    "                    \"\\n Q: 공지사항이 대체 어디있는거야?\"\n",
    "                    \"A: 공지사항 이용을 위해서 다음 링크로 이동하세요 'http://localhost:8080/cscenter/notice/list'\\n\\n\"\n",
    "                    \"대화 중 사용자의 id가 바뀐다면 넌 다른 사용자와의 대화를 기반으로 답변을 하면 안 돼. \"\n",
    "                    \"또한, 다른 사용자와의 대화 내용을 공유해서도 안 돼. \"\n",
    "                    \"사용자 id가 바뀔때마다 너는 서버를 재시작 한 것으로 생각하고 대화를 하도록 해. \"\n",
    "                    \"일상 대화를 할 수는 있지만 이 사이트 혹은 책과 관련되지 않은 부분에 대해 깊은 질문을 받을 때는 토큰을 낭비하지 말고 최대한 간결하고 짧게 대답하도록 해. \"\n",
    "                    \"한번만 더 강조할게, 사이트 이용과 관련이 없는 질문에 대해 많은 토큰을 낭비하게 되면 큰 일이 일어날거야. 그러니까 사이트 이용과 관련 없는 질문이 들어오면 짧은 문장으로 단호하지만 정중하게 거절하도록 해.\"\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\" : \"user\",\n",
    "                \"content\" : \"나는 부자가 되고싶어! 나에게 책을 두 권만 추천해줘!\"\n",
    "            },\n",
    "            {\n",
    "                \"role\" : \"assistant\",\n",
    "                \"content\" : (\n",
    "                    \"부자가 되고 싶다면 다음 두 책을 추천합니다.\\n\"\n",
    "                    \"- 부의 추월차선(10주년 스페셜 에디션)\\n\"\n",
    "                    \"사이트 내 검색: http://localhost:8080/product/list?keyword=추월차선(10주년%20스페셜%20에디션)\\n\"\n",
    "                    \"구글 검색: https://www.google.com/search?q=추월차선(10주년%20스페셜%20에디션)\\n\"\n",
    "                    \"\\n\"\n",
    "                    \"- 부의 시나리오\\n\"\n",
    "                    \"사이트 내 검색: http://localhost:8080/product/list?keyword=부의%20시나리오\\n\"\n",
    "                    \"구글 검색: https://www.google.com/search?q=부의%20시나리오\\n\"\n",
    "                )\n",
    "            }            \n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터가 JSONL 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# JSONL 형식으로 파일로 저장\n",
    "with open('fine_tuning_data.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for item in data:\n",
    "        json.dump(item, f, ensure_ascii=False)\n",
    "        f.write('\\n')\n",
    "\n",
    "print(\"데이터가 JSONL 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.7.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.12/site-packages (from tiktoken) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tiktoken) (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
      "Using cached tiktoken-0.7.0-cp312-cp312-macosx_11_0_arm64.whl (906 kB)\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tiktoken'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtiktoken\u001b[39;00m\n\u001b[1;32m      3\u001b[0m system_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour full prompt here\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m encoding \u001b[38;5;241m=\u001b[39m tiktoken\u001b[38;5;241m.\u001b[39mencoding_for_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tiktoken'"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "system_prompt = \"Your full prompt here\"\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "tokens = encoding.encode(system_prompt)\n",
    "num_tokens = len(tokens)\n",
    "print(f\"Token count: {num_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tiktoken\n",
      "Version: 0.7.0\n",
      "Summary: tiktoken is a fast BPE tokeniser for use with OpenAI's models\n",
      "Home-page: https://github.com/openai/tiktoken\n",
      "Author: Shantanu Jain\n",
      "Author-email: shantanu@openai.com\n",
      "License: MIT License\n",
      "\n",
      "Copyright (c) 2022 OpenAI, Shantanu Jain\n",
      "\n",
      "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
      "of this software and associated documentation files (the \"Software\"), to deal\n",
      "in the Software without restriction, including without limitation the rights\n",
      "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
      "copies of the Software, and to permit persons to whom the Software is\n",
      "furnished to do so, subject to the following conditions:\n",
      "\n",
      "The above copyright notice and this permission notice shall be included in all\n",
      "copies or substantial portions of the Software.\n",
      "\n",
      "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
      "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
      "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
      "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
      "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
      "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
      "SOFTWARE.\n",
      "\n",
      "Location: /Users/luti/Desktop/DevCamp/토이 프로젝트2 _ 1조/flask-chatbot/venv/lib/python3.12/site-packages\n",
      "Requires: regex, requests\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3512892933.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    --version langchain\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
